// vim: set ft=groovy:

//#################
// Global Variables
//#################

// pipeline config
projectName="vib-main"
artifactName='SilKit'
keepNumBuilds=10 //number of log files on Jenkins, workspaces are always cleaned
publishToArtifactory=false
buildDebugBin=false //debug binaries are only build when doing a release to customers
buildWarningsAsErrors=true // compiler warnings are treated as errors
// artifactory for archiving / packaging
artifactoryServer = Artifactory.server('IntegrationBusArtifactory')
artifactoryBuildInfo = Artifactory.newBuildInfo()

def gitBranch="master" // overriden in parallel pipeline based on scm vars

def buildConfigs = [
    // Windows builds:
    [

        Name: "VS2017-Win64",
        NodeLabel: "ninja && buildtools2019",
        Arch:"x64",
        MsvcVersion:"14.1",
        PublishArtifacts: true,
        CmakeArgs: ""
    ]
    ,[
        Name:"VS2015-Win64",
        NodeLabel: "ninja && buildtools2019",
        Arch:"x64",
        MsvcVersion:"14.0",
        PublishArtifacts: true,
        CmakeArgs: "",
    ]
    ,[
        Name: "VS2017-Win32",
        NodeLabel: "ninja && buildtools2019",
        Arch:"x64_x86",
        MsvcVersion:"14.1",
        PublishArtifacts: true,
        CmakeArgs: "",
    ]
    ,[
        Name: "VS2015-Win32",
        NodeLabel: "ninja && buildtools2019",
        Arch:"x64_x86",
        MsvcVersion:"14.0",
        PublishArtifacts: true,
        CmakeArgs: "",
    ]

    ,[
        Name: "MinGW", // We cross compile from ubuntu to windows
        NodeLabel: "docker && windows",
        DockerImage: "vib-windows",
        //DockerBuildArgs: "--build-arg UBUNTU_VERSION=20.04",
        PublishArtifacts: true,
        CmakeArgs: " -D CMAKE_C_COMPILER=C:/mingw64/bin/x86_64-w64-mingw32-gcc.exe  -D CMAKE_CXX_COMPILER=C:/mingw64/bin/x86_64-w64-mingw32-g++.exe",
        WarningsAsErrors: false, // we have some spurious warnings here, will be ignored
    ]

    // Linux builds:
    ,[
        Name: "Ubuntu-18.04-clang",
        NodeLabel: "docker && linux",
        DockerImage: "vib-ubuntu",
        DockerBuildArgs: "--build-arg UBUNTU_VERSION=18.04",
        PublishArtifacts: false,
        CmakeArgs: "-D CMAKE_C_COMPILER=clang -D CMAKE_CXX_COMPILER=clang++",
    ]
    ,[
        Name: "Ubuntu-18.04-gcc",
        NodeLabel: "docker && linux",
        DockerImage: "vib-ubuntu",
        DockerBuildArgs: "--build-arg UBUNTU_VERSION=18.04",
        PublishArtifacts: true,
        CmakeArgs: "-D CMAKE_C_COMPILER=gcc -D CMAKE_CXX_COMPILER=g++",
    ]
    ,[
        Name: "Ubuntu-20.04-gcc-10",
        NodeLabel: "docker && linux",
        DockerImage: "vib-ubuntu",
        DockerBuildArgs: "--build-arg UBUNTU_VERSION=20.04",
        PublishArtifacts: false,
        CmakeArgs: "-D CMAKE_C_COMPILER=gcc-10 -D CMAKE_CXX_COMPILER=g++-10",
    ]
    ,[
        Name: "Ubuntu-20.04-clang-12",
        NodeLabel: "docker && linux",
        DockerImage: "vib-ubuntu",
        DockerBuildArgs: "--build-arg UBUNTU_VERSION=20.04",
        PublishArtifacts: false,
        CmakeArgs: "-D CMAKE_C_COMPILER=clang-12 -D CMAKE_CXX_COMPILER=clang++-12",
    ]
    // Sanitizer builds:
    ,[
        Name: "Ubuntu-thread-sanitizer",
        NodeLabel: "docker && linux",
        DockerImage: "vib-ubuntu",
        DockerBuildArgs: "--build-arg UBUNTU_VERSION=20.04",
        PublishArtifacts: false,
        CmakeArgs: "-D CMAKE_C_COMPILER=clang-12 -D CMAKE_CXX_COMPILER=clang++-12 -D SILKIT_ENABLE_THREADSAN=ON",
    ]
    ,[
        Name: "Ubuntu-address-sanitizer",
        NodeLabel: "docker && linux",
        DockerImage: "vib-ubuntu",
        DockerBuildArgs: "--build-arg UBUNTU_VERSION=20.04",
        PublishArtifacts: false,
        CmakeArgs: "-D CMAKE_C_COMPILER=clang-12 -D CMAKE_CXX_COMPILER=clang++-12 -D SILKIT_ENABLE_ASAN=ON",
    ]
]


//##########################################
// Utilities
//##########################################
@NonCPS
def isFullBuildRequired(branchName) {
    // Master and Pull Requests are always full builds
    if(branchName == 'master' || branchName.startsWith("PR-")) {
        return true;
    }
    // A user requests a fullbuild by adding a "/full" suffix
    if(branchName.contains("/full")) {
        return true;
    }
    return false
}

@NonCPS
def isDockerNode(label) {
    return label.toUpperCase().contains('DOCKER')
}

@NonCPS
def isClangBuild(label) {
    return label.toUpperCase().contains('CLANG')
}

def setBuildRetention(bi) {
    if(gitBranch == 'master' || gitBranch == 'origin/master') {
        bi.retention(maxBuilds: 40, deleteBuildArtifacts: true, async: true)
    } else {
        bi.retention(maxBuilds: 2, maxDays: 50, deleteBuildArtifacts: true, async: true)
    }
}

//recursive submodule git checkout 
def checkoutGit() {
    return checkout([$class: 'GitSCM',
            branches: scm.branches,
            doGenerateSubmoduleConfigurations: false,
            extensions: [
                [$class: 'SubmoduleOption',
                    disableSubmodules: false,
                    parentCredentials: false,
                    recursiveSubmodules: true,
                    reference: '',
                    trackingSubmodules: false]],
            submoduleCfg: [],
            userRemoteConfigs: scm.userRemoteConfigs
        ])
}
def shallowCheckoutGit() {
    return checkout([$class: 'GitSCM',
            branches: scm.branches,
            doGenerateSubmoduleConfigurations: false,
            userRemoteConfigs: scm.userRemoteConfigs
        ])
}

def archiveToArtifactory(config, scm, pattern) {
    //find the file to upload
    if (! publishToArtifactory ) {
        print("INFO: skipping publishing ${config.Name} to artifactory because of user request")
        return
    }
    if(! config["PublishArtifacts"]) {
        print("INFO: skipping publishing ${config.Name} to artifactory because of config")
        return
    }

    def files = findFiles(glob: pattern)
    if(files.size() != 1) {
        error("ERROR: single file ${pattern} required: findFiles returned: ${files}")
    } else {

        print("INFO: found build artifact ${files[0]}")
        def fileName = files[0].name

        configFileProvider(
            [configFile(fileId: 'SILKIT_ARTIFACTORY_REPO', variable: 'SILKIT_ARTIFACTORY_REPO')]) {
            def repo = readFile(file: SILKIT_ARTIFACTORY_REPO).trim()
            def spec = """{
                "files": [{
                    "pattern": "${files[0]}",
                    "target" : "${repo}/${projectName}/${scm.GIT_BRANCH}/${scm.GIT_COMMIT}/${fileName}",
                    "props"  : "git_commit=${scm.GIT_COMMIT};git_branch=${scm.GIT_BRANCH};git_url=${scm.GIT_URL}"
            }]}"""
            print("artifactory spec=${spec}")
            def buildInfo = artifactoryServer.upload(
                spec: spec,
                failNoOp: true
            )
            setBuildRetention(buildInfo)
            artifactoryBuildInfo.append(buildInfo)
        }
    }
}

def buildDocker(config) {
    stage("Building Docker Image") {
        def dockerImage = config["DockerImage"]
        def dockerDir = "./SilKit/ci/docker"
        def buildArgs = "--build-arg ARTIFACTORY=${artifactoryServer.url} "

        configFileProvider([
            configFile(fileId: 'VECTOR_DOCKER_REGISTRY', variable: 'VECTOR_DOCKER_REGISTRY'),
            configFile(fileId: 'SILKIT_ARTIFACTORY_REPO', variable: 'SILKIT_ARTIFACTORY_REPO'),
            configFile(fileId: 'PROXY_DOMAIN', variable: 'PROXY_DOMAIN'),
            ]) {
            def registry = readFile(file: VECTOR_DOCKER_REGISTRY).trim()
            buildArgs += " --build-arg REGISTRY=${registry} "

            def repo = readFile(file: SILKIT_ARTIFACTORY_REPO).trim()
            buildArgs += " --build-arg SILKIT_ARTIFACTORY_REPO=${repo} "

            def proxyDomain = readFile(file: PROXY_DOMAIN).trim()
            buildArgs += " --build-arg PROXY_DOMAIN=${proxyDomain} "

            print("Building docker image ${dockerImage}")
            if(config.containsKey("DockerBuildArgs")) {
                buildArgs += config["DockerBuildArgs"]
            }
            // We assume the docker file (located in the docker subfolder) is named exactly like the docker image
            buildArgs += " -f ${dockerDir}/${dockerImage} ${dockerDir}"
            docker.build(dockerImage, buildArgs)
        }
    }
}
// runOnNode: a helper that runs the userStages closure on an appropriate node
// i.e., this allows running the same stages on docker and windows
def runOnNode(config, userStages) {
    def buildName = config["Name"]
    def wsDir = "workspace/${env.JOB_NAME}/" \
                 + buildName.replaceAll(" ", "_") + "_${env.BUILD_NUMBER}"
    return {
        node(config["NodeLabel"]) {
            ws(wsDir) {
                try {
                    if(isDockerNode(config["NodeLabel"])) {
                        //the built image should be cached and shared anyway
                        shallowCheckoutGit()
                        print("Calling docker inside in ${pwd()}")
                        buildDocker(config)
                        docker.image(config["DockerImage"]).inside {
                            userStages()
                        }
                    } else {
                        print("Working in ${pwd()}")
                        userStages()
                    }
                } finally {
                    cleanWs(cleanWhenNotBuilt: true, cleanWhenFailure: true,
                            cleanWhenSuccess: true, cleanWhenAborted: true,
                            deleteDirs: true, disableDeferredWipeout: true)
                }
            } //ws
        } //node
    } //return
}

// Canonical way on CMake + Ninja + VS is to source the appropriate vcvarsall script
// before invoking cmake -G Ninja
def getVsBuildEnv(arch, version){
    def localEnv=[]
    def toolDir="${tool 'BuildTools2019'}\\..\\..\\.."
    // get vcvarsall.bat environment
    def envstr = bat returnStdout: true, script: "\"${toolDir}\\VC\\Auxiliary\\Build\\vcvarsall.bat\" ${arch} -vcvars_ver=${version} &set"
    def lines = envstr.split("\r\n")
    for(int i = 0; i < lines.size(); i++) {
        def line = lines[i]
        if(line =~ /^\S+=.*/) {
            localEnv += line
        }
    }
    return localEnv
}

//helper to invoke  cmake platform independently with uniform arguments
def runCmake(config, buildType) {
    def cmakeArgs = config["CmakeArgs"]
    cmakeArgs += " -DCMAKE_EXPORT_NO_PACKAGE_REGISTRY=ON "

    if(buildType == "Release") {
        //only distribute source and docs in release mode
        cmakeArgs +=" -DSILKIT_INSTALL_SOURCE=ON "
    }

    if (config.containsKey("WarningsAsErrors")) {
        def isEnabled = config["WarningsAsErrors"].toBoolean()
        if(isEnabled) {
            print("Enabling Warnings-as-Errors for the current build config")
            cmakeArgs +=" -DSILKIT_WARNINGS_AS_ERRORS=ON "
        } else {
            print("Disabling Warnings-as-Errors for the current build config")
        }
    } else {
         if (buildWarningsAsErrors ) {
            print("Setting Build with Warnings as Errors (globally set)")
            cmakeArgs +=" -DSILKIT_WARNINGS_AS_ERRORS=ON "
        }
    }

    // Add CL compiler for VS (MS Visual Studio) builds
    if(config["Name"] =~ /^VS/) {
        cmakeArgs += " -D CMAKE_C_COMPILER=cl -D CMAKE_CXX_COMPILER=cl"
        def msvcVersion = config["MsvcVersion"]
        cmakeArgs += " -DMSVC_TOOLSET_VERSION=${msvcVersion}" //needed for binary download URL resolution
    }

    cmakeBuild(
        installation: 'InSearchPath',
        cleanBuild: true,
        buildType: "${buildType}",
        buildDir: "_build_${buildType}",
        generator: "Ninja",
        cmakeArgs: "${cmakeArgs} -DCMAKE_BUILD_TYPE=${buildType} ",
        steps: [[args: "--target package --config ${buildType}  --parallel", withCmake: true]]
    )
}

def run(what) {
    if(isUnix()) {
        sh "${what}"
    } else {
        bat "${what}"
    }
}
// quote percent sign for DOS batch, eg. uses in git log --format=%ct
def quoteBat(userStr) {
    def res="@" //disable printing the command itself
    for(int i = 0; i < userStr.size(); i++) {
        def ch = userStr[i]
        if( ch == '%' ) {
            res += "%%"
        } else{
            res += ch
        }
    }
    return res
}
def runWithOutput(what) {
    if(isUnix()) {
        return sh(script: "${what}", returnStdout: true).trim()
    } else {
        return bat(script: "${quoteBat(what)}", returnStdout: true).trim()
    }
}

//##########################################
//the actual build process
//##########################################

// instantiate a build on an appropriate node
def doBuild(Map config) {
    return runOnNode(config, {
        def buildName = config["Name"]

        def buildEnv = []
        def scmVars = [:]

        stage("Git checkout and ENV setup (${buildName})") {
            if(config.containsKey("MsvcVersion")) {
                // visual studio toolset selection via vcvarsall env
                buildEnv = buildEnv + getVsBuildEnv(config["Arch"], config["MsvcVersion"])
                buildEnv.add("MSBUILDDISABLENODEREUSE=1") //fixes spurious windows failures
            }

            scmVars = checkoutGit()

            // For reproducible build set SOURCE_DATE_EPOCH to time of last commit
            def commitTime = runWithOutput("git log --max-count=1 --format=%ct -r origin/master")
            print("DEBUG scmVars=${scmVars}, commitTime=${commitTime}, TZ=${env.TZ}, LC_ALL=${env.LC_ALL}")
            buildEnv.add("SOURCE_DATE_EPOCH=${commitTime}")
            buildEnv.add("TZ=UTC")
            buildEnv.add("LC_ALL=C")
            buildEnv.add("LANG=C")
            // save branch name for publishing stage
            gitBranch = scmVars.GIT_BRANCH
        }

        stage("Cmake Release Build (${buildName})") {
            print("${buildName} --  running cmake Release")
            withEnv(buildEnv) {
                print("Debug: TZ=${env.TZ} LC_ALL=${env.LC_ALL}")
                runCmake(config, "Release" )
            }
        }

        // Skip Tests when cross-building        
        def isCrossBuild  = false
        if(config.containsKey("IsCrossBuild")) {
            isCrossBuild = config["IsCrossBuild"]
        }

        if(isCrossBuild) {
            print("${buildName} --  skipping tests in crossbuild")
        } else {
            stage("Unit Tests Release (${buildName})") {
                dir("_build_Release") {

                    timeout(time: 10, unit: 'MINUTES') {
                        ctest(
                            installation: 'InSearchPath',
                            arguments: "--verbose --build-config Release -R '^Test.*'"
                        )
                    }
                    junit("**/*gtestresults.xml")

                }
            }

            stage("Integration Tests Release (${buildName})") {
                dir("_build_Release") {
                    timeout(time: 10, unit: 'MINUTES') {
                        ctest(
                            installation: 'InSearchPath',
                            arguments: "--verbose --build-config Release -R '^ITest.*'"
                        )
                    }
                    junit("**/*gtestresults.xml")

                }
            }
        }

        if(buildDebugBin) {
            stage("Cmake Debug Build (${buildName})") {
                print("${buildName} --  running cmake Debug")
                withEnv(buildEnv) {
                    runCmake(config, "Debug")
                }
            }
        } else {
            print("Skipping Debug Build")
        }

        if(publishToArtifactory ) {
            stage(" Bundle and Archive Packages (${buildName})") {
                run "python ./SilKit/ci/package.py \"_build_Release/${artifactName}-*-Release.zip\" \"_build_Debug/${artifactName}-*-Debug.zip\""
                archiveToArtifactory(config, scmVars, "${artifactName}-*.zip")

                // safe the PDB files on windows
                if(!isUnix()) {
                    // package PDB files without rebuilding
                    def pdbArchive = "_build_Debug/SilKit-${buildName}-PDB.zip"
                    run "python -mzipfile -c ${pdbArchive} _build_Debug/package-pdb/ _build_Release/package-pdb/"
                    archiveToArtifactory(config, scmVars, pdbArchive)
                }
            }
        }
    })
}

// node main entry. parallel invocation of all builds, packaging
node {
    try {
        properties([
            buildDiscarder(logRotator(numToKeepStr: "${keepNumBuilds}")),
            parameters([
                booleanParam(name: "ForceFullBuild", defaultValue: false,
                    description: "Force a full build with artificat uploads")
                ,booleanParam(name: "ForceArtifactUpload", defaultValue: false,
                    description: "Force uploading artifact uploads")
                ,booleanParam(name: "UseThreadSanitizer", defaultValue: false,
                    description: "Build with thread sanitizer, pelase refer to the  output logs of tests")
                ,booleanParam(name: "UseAddressSanitizer", defaultValue: false,
                    description: "Build with thread sanitizer, pelase refer to the  output logs of tests")
            ])
        ])  

        def doFullBuild = isFullBuildRequired(env.BRANCH_NAME)
        if(params.ForceFullBuild) {
            print("Forcing a full build at user request!")
            doFullBuild = true
        }

        def configNames = []

        if(params.UseAddressSanitizer) {
            print("Building on Ubuntu with -f sanitizer=thread")
            configNames = [
                "Ubuntu-thread-sanitizer"
            ]
        }
        else if (params.UseThreadSanitizer) {
            print("Building on Ubuntu with -f sanitizer=address")
            configNames = [
                "Ubuntu-address-sanitizer"
            ]
        }
        else if(doFullBuild) {
            print("Doing a full build and publishing artifacts on branch ${env.BRANCH_NAME}")
            configNames = [
                "VS2015-Win32",
                "VS2015-Win64",
                "VS2017-Win32",
                "VS2017-Win64",
                "Ubuntu-18.04-gcc",
                "Ubuntu-20.04-clang-12", // most modern compiler, no artifacts
                //"MinGW", // XXX disabled until we can improve CI performance
            ]
            publishToArtifactory = true
            buildDebugBin = true
        } else {
            print("Doing a minimal build without publishing artifacts on branch ${env.BRANCH_NAME}")
            configNames = [
                "VS2015-Win32", // out of date implementation of C++14
                "Ubuntu-20.04-clang-12", // most modern compiler
            ]
        }
        def builds = [:]
        configNames.each {
            def configName = it
            def buildConfig = buildConfigs.find { it.Name == configName}
            if(params.ForceArtifactUpload) {
                print("ForceArtifactUpload: PublishArtifacts is enabled for ${configName}")
                buildConfig["PublishArtifacts"] = true
                buildDebugBin = true
            } else {
                if(!doFullBuild) {
                    print("PublishArtifacts is disabled for ${configName}")
                    buildConfig["PublishArtifacts"] = false
                }
            }
            builds.put(it, doBuild(buildConfig))
        }

        if(params.ForceArtifactUpload) {
            print("Forcing Artifact Upload")
            publishToArtifactory = true
        }

        parallel(builds)

    }
    finally {
        if(publishToArtifactory) {
            stage("Publishing Build Info") {
                print("INFO: publishing artifactory build info for branch ${gitBranch}")
                setBuildRetention(artifactoryBuildInfo)
                artifactoryServer.publishBuildInfo(artifactoryBuildInfo)
            }
        } else {
            stage("Done (No Publishing)") {
                print("INFO: not publishing artifacts")
            }
        }
        cleanWs(cleanWhenNotBuilt: true, cleanWhenFailure: true,
                cleanWhenSuccess: true, cleanWhenAborted: true,
                deleteDirs: true, disableDeferredWipeout: true )
    }
}
