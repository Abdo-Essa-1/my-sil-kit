// vim: set ft=groovy:
// a simple cmake and ctest  CI file

//##########################################
// modify these top level variables to change the build targets and cmake options
//##########################################
// pipeline config
projectName="vib-main"
artifactName='IntegrationBus'
keepNumBuilds=5
publishToArtifactory=true
//debug binaries are only build when doing a release to customers
buildDebugBin=true
cleanBuild=true

// add new build targets here
buildTargets = [
    // Name of the target : ["node label", "generator name"]
    "VS2017-Win64"     : ["windows", "Visual Studio 15 2017 Win64"]
    ,"VS2015-Win64"     : ["windows", "Visual Studio 14 2015 Win64"]
    ,"VS2017-x32"       : ["windows", "Visual Studio 15 2017"]
    ,"VS2015-x32"       : ["windows", "Visual Studio 14 2015"]
    ,"Ubuntu-gcc"        : ["docker && linux", "Ninja"]
    ,"Ubuntu-clang"      : ["docker && linux", "Ninja"]
]

//linux docker image
dockerImage ="vib/ubuntu"
dockerImageDir ="./IntegrationBus/ci" //for packaging additional files in docker, e.g. "."
dockerImageFile ="${dockerImageDir}/Dockerfile.vib-ubuntu"
dockerImageTag ="18.04"
// artifactory for archiving / packaging
artifactoryServer = Artifactory.server('IntegrationBusArtifactory')
artifactoryRepo = '***VIB-820 Removed***'
artifactoryBuildInfo = Artifactory.newBuildInfo()

//  global cmake args for all builds
cmakeArgsRelease="-DIB_INSTALL_SOURCE=ON " //only distribute source and docs in release mode
cmakeArgs ="-DIB_BIN_FASTRTPS_ENABLE=ON \
    -DIB_BIN_FASTRTPS_REPOSITORY=\"${artifactoryServer.url}/${artifactoryRepo}/ThirdParty/FastRTPS\" \
    "
//##########################################
// Utilities
//##########################################
def isDockerNode(label) {
    return label.toUpperCase().contains('DOCKER')
}
def isClangBuild(label) {
    return label.toUpperCase().contains('CLANG')
}
//recursive submodule git checkout 
def checkoutGit() {
    return checkout([$class: 'GitSCM',
            branches: scm.branches,
            doGenerateSubmoduleConfigurations: false,
            extensions: [
                [$class: 'SubmoduleOption',
                    disableSubmodules: false,
                    parentCredentials: false,
                    recursiveSubmodules: true,
                    reference: '',
                    trackingSubmodules: false]],
            submoduleCfg: [],
            userRemoteConfigs: scm.userRemoteConfigs
        ])
}
def shallowCheckoutGit() {
    return checkout([$class: 'GitSCM',
            branches: scm.branches,
            doGenerateSubmoduleConfigurations: false,
            userRemoteConfigs: scm.userRemoteConfigs
        ])
}
def archiveToArtifactory(pattern) {
    //find the file to upload
    def files = findFiles(glob: pattern)
    if(files.size() != 1) {
        error("ERROR: single file ${pattern} required: findFiles returned: ${files}")
    } else {
        print("INFO: found build artifact ${files[0]}")
        if (! publishToArtifactory ) {
            print("INFO: skipping publishing to artifactory because of user request")
            return
        }

        fileName = files[0].name
        spec = """{
            "files": [{
                "pattern": "${files[0]}",
                "target" : "${artifactoryRepo}/${projectName}/${env.GIT_BRANCH}/${env.GIT_COMMIT}/${fileName}",
                "props"  : "git_commit=${env.GIT_COMMIT};git_branch=${env.GIT_BRANCH};git_url=${env.GIT_URL}"
        }]}"""
        print("artifactory spec=${spec}")
        buildInfo = artifactoryServer.upload(
            spec: spec,
            failNoOp: true
        )
        artifactoryBuildInfo.append(buildInfo)
    }
}
// runOnNode: a helper that runs the userStages closure on an appropriate node
// i.e., this allows running the same stages on docker and windows
def runOnNode(buildName, buildAgent, userStages) {
    return {
        node(buildAgent) {
            // make sure the steps/stages are executed in a separate, clean workspace
            wsDir = "workspace/${env.JOB_NAME}/${env.BUILD_NUMBER}/" + buildName.replaceAll(" ", "_")
            if(isDockerNode(buildAgent)) {
                //the built image should be cached and shared anyway
                stage("${buildName}: build docker image") {
                    // initial checkout in master node so we can access the ci files
                    shallowCheckoutGit()
                    docker.build(dockerImage,  //XXX this might require a checkout for ./ci to be present
                            "--build-arg ARTIFACTORY=${artifactoryServer.url} -f ${dockerImageFile} ${dockerImageDir}")
                }
                ws(wsDir) {
                    curDir=pwd()
                    print("Calling docker inside in ${curDir}")
                    docker.image(dockerImage).inside {
                        userStages()
                        cleanWs()
                    }
                }
            } else {
                ws(wsDir) {
                    curDir=pwd()
                    print("Working in ${curDir}")
                    userStages()
                    cleanWs()
                }
            }
        }
    }
}
//helper to invoke  cmake platform independently with uniform arguments
def runCmake(buildTool, buildType, extraArgs="") {
    cmakeBuild(
        installation: 'InSearchPath',
        cleanBuild: cleanBuild,
        buildType: "${buildType}",
        buildDir: "_build_${buildType}",
        generator: "${buildTool}",
        cmakeArgs: "${cmakeArgs} -DCMAKE_BUILD_TYPE=${buildType} ${extraArgs}",
        steps: [[args: "--target package --config ${buildType}  --parallel", withCmake: true]]
    )
}
def run(what) {
    if(isUnix()) {
        sh "${what}"
    } else {
        bat "${what}"
    }
}

//##########################################
//the actual build process
//##########################################

// instantiate a build on an appropriate node
def doBuild(buildName, buildAgent, buildTool) {
    return runOnNode(buildName, buildAgent, {
        def scmEnv = []
        stage("${buildName}: scm checkout") {
            scmVars = checkoutGit()
            scmEnv.add("GIT_BRANCH=${scmVars.GIT_BRANCH}")
            scmEnv.add("GIT_COMMIT=${scmVars.GIT_COMMIT}")
            scmEnv.add("GIT_URL=${scmVars.GIT_URL}")
            scmEnv.add("MSBUILDDISABLENODEREUSE=1") //fixes spurious windows failures
            if(isClangBuild(buildName)) {
                scmEnv.add("CC=clang")
                scmEnv.add("CXX=clang++")
            } else {
                scmEnv.add("CC=gcc")
                scmEnv.add("CXX=g++")
            }
            print("DEBUG scmVars=${scmVars}")
        }
        withEnv(scmEnv) {
            stage("${buildName}: cmake build Release") {
                def ccArgs="${cmakeArgsRelease}"
                if(isClangBuild(buildName)) {
                    print("setting cmake compiler to clang")
                    ccArgs+=" -DCMAKE_CXX_COMPILER='clang++' -DCMAKE_C_COMPILER=clang"
                }
                print("running cmake")
                runCmake(buildTool, "Release", ccArgs)
            }
            stage("${buildName}: Unit Tests Release") {
                dir("_build_Release") {
                    ctest(
                        installation: 'InSearchPath',
                        arguments: "--build-config Release -R '^Test.*'"
                    )
                    junit("**/*gtestresults.xml")

                }
            }
            stage("${buildName}: Integration Tests Release ") {
                dir("_build_Release") {
                    try {
                        timeout(time: 2, unit: 'MINUTES') {
                            ctest(
                                installation: 'InSearchPath',
                                arguments: "--build-config Release -R '^ITest.*'"
                            )
                        }
                        junit("**/*gtestresults.xml")
                    } catch(e) {
                        print("WARNING: integration tests failed with: ${e}")
                    }

                }
            }
            stage("${buildName}: archiving Release Build") {
                try {
                    archiveToArtifactory("_build_Release/${artifactName}-*.zip")
                } catch(e) {
                    //make sure we save the finished artifacts before failing the build 
                    print("WARNING: archiving to artifactory failed, archiving to jenkins instead and failing: exception: ${e}")
                    archiveArtifacts(artifacts: "_build_Release/${artifactName}-*.zip", fingerprint: true)
                    throw e
                }
            }
            if(buildDebugBin) {
                stage("${buildName}: cmake Debug bundle") {
                    def ccArgs=""
                    if(isClangBuild(buildName)) {
                        ccArgs="-DCMAKE_CXX_COMPILER=clang++ -DCMAKE_C_COMPILER=clang"
                    }
                    runCmake(buildTool, "Debug", ccArgs)
                    run "python ${dockerImageDir}/package.py  \"_build_Debug/${artifactName}-*-Debug.zip\" \"_build_Release/${artifactName}-*-Release.zip\""
                    archiveToArtifactory("_build_Debug/${artifactName}-*.zip")
                    archiveToArtifactory("${artifactName}-*.zip")
                }
            }
        }
    })
}

// node main entry. parallel invocation of all builds, packaging
node {
    // pipeline settings
    properties([
        buildDiscarder(logRotator(numToKeep: keepNumBuilds)),
    ])
    //create all parallel build stages
    def builds =[:]
    // workaround for https://issues.jenkins-ci.org/browse/JENKINS-49732
    buildTargets.each { e ->
        print("runCmakePipeline: ${e.key} -> ${e.value}")
        builds[e.key] = doBuild(e.key, e.value[0], e.value[1])
    }
    parallel(builds)

    stage("Publishing Build Info") {
        if(publishToArtifactory) {
            artifactoryServer.publishBuildInfo(artifactoryBuildInfo)
        } else {
            print("INFO: skipping publishing build info to artifactory because of user request")
        }
    }
}
