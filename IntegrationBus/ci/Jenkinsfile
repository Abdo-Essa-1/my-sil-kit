// vim: set ft=groovy:
// a simple cmake and ctest  CI file

//##########################################
// modify these top level variables to change the build targets and cmake options
//##########################################
// pipeline config
projectName="vib-main"
artifactName='IntegrationBus'
keepNumBuilds=5
publishToArtifactory=true
//debug binaries are only build when doing a release to customers
buildDebugBin=true
cleanBuild=true

//linux docker image
dockerImage ="vib/ubuntu"
dockerImageDir ="./IntegrationBus/ci" //for packaging additional files in docker, e.g. "."
dockerImageFile ="${dockerImageDir}/Dockerfile.vib-ubuntu"
dockerImageTag ="18.04"
// artifactory for archiving / packaging
artifactoryServer = Artifactory.server('IntegrationBusArtifactory')
artifactoryRepo = '***VIB-820 Removed***'
artifactoryBuildInfo = Artifactory.newBuildInfo()

//  global cmake args for all builds
cmakeArgsRelease="-DIB_INSTALL_SOURCE=ON " //only distribute source and docs in release mode
cmakeArgs ="-DIB_BIN_FASTRTPS_ENABLE=ON \
    -DIB_BIN_FASTRTPS_REPOSITORY=\"${artifactoryServer.url}/${artifactoryRepo}/ThirdParty/FastRTPS\" \
    "
//##########################################
// Utilities
//##########################################
def isDockerNode(label) {
    return label.toUpperCase().contains('DOCKER')
}

def isClangBuild(label) {
    return label.toUpperCase().contains('CLANG')
}


//recursive submodule git checkout 
def checkoutGit() {
    return checkout([$class: 'GitSCM',
            branches: scm.branches,
            doGenerateSubmoduleConfigurations: false,
            extensions: [
                [$class: 'SubmoduleOption',
                    disableSubmodules: false,
                    parentCredentials: false,
                    recursiveSubmodules: true,
                    reference: '',
                    trackingSubmodules: false]],
            submoduleCfg: [],
            userRemoteConfigs: scm.userRemoteConfigs
        ])
}
def shallowCheckoutGit() {
    return checkout([$class: 'GitSCM',
            branches: scm.branches,
            doGenerateSubmoduleConfigurations: false,
            userRemoteConfigs: scm.userRemoteConfigs
        ])
}

def archiveToArtifactory(scm, pattern) {
    //find the file to upload
    def files = findFiles(glob: pattern)
    if(files.size() != 1) {
        error("ERROR: single file ${pattern} required: findFiles returned: ${files}")
    } else {
        print("INFO: found build artifact ${files[0]}")
        if (! publishToArtifactory ) {
            print("INFO: skipping publishing to artifactory because of user request")
            return
        }

        fileName = files[0].name
        spec = """{
            "files": [{
                "pattern": "${files[0]}",
                "target" : "${artifactoryRepo}/${projectName}/${scm.GIT_BRANCH}/${scm.GIT_COMMIT}/${fileName}",
                "props"  : "git_commit=${scm.GIT_COMMIT};git_branch=${scm.GIT_BRANCH};git_url=${scm.GIT_URL}"
        }]}"""
        print("artifactory spec=${spec}")
        buildInfo = artifactoryServer.upload(
            spec: spec,
            failNoOp: true
        )
        artifactoryBuildInfo.append(buildInfo)
    }
}

// runOnNode: a helper that runs the userStages closure on an appropriate node
// i.e., this allows running the same stages on docker and windows
def runOnNode(buildName, buildAgent, userStages) {    
    // make sure the steps/stages are executed in a separate, clean workspace
    def wsDir = "workspace/${env.JOB_NAME}/${env.BUILD_NUMBER}/" + buildName.replaceAll(" ", "_")
    
    return {
        node(buildAgent) {            
            if(isDockerNode(buildAgent)) {
                //the built image should be cached and shared anyway
                stage("${buildName}: build docker image") {
                    // initial checkout in master node so we can access the ci files
                    shallowCheckoutGit()
                    docker.build(dockerImage,  //XXX this might require a checkout for ./ci to be present
                            "--build-arg ARTIFACTORY=${artifactoryServer.url} -f ${dockerImageFile} ${dockerImageDir}")
                }
                ws(wsDir) {
                    curDir=pwd()
                    print("Calling docker inside in ${curDir}")
                    docker.image(dockerImage).inside {
                        userStages()
                        cleanWs()
                    }
                }
            } else {
                ws(wsDir) {
                    curDir=pwd()
                    print("Working in ${curDir}")
                    userStages()
                    cleanWs()
                }
            }
        }
    }
}

// Canonical way on CMake + Ninja + VS is to source the appropriate vcvarsall script
// before invoking cmake -G Ninja
def getVsBuildEnv(arch, version){
    def localEnv=[]
    toolDir="${tool 'BuildTools2019'}\\..\\..\\.."
    // get vcvarsall.bat environment
    envstr = bat returnStdout: true, script: "\"${toolDir}\\VC\\Auxiliary\\Build\\vcvarsall.bat\" ${arch} -vcvars_ver=${version} &set" 
    for(line in envstr.split("\r\n")) {
            if(line =~ /^\S+=.*/) {
                localEnv += line
        }
    }
    return localEnv
}

//helper to invoke  cmake platform independently with uniform arguments
def runCmake(buildType, extraArgs=""){
    cmakeBuild(
        installation: 'InSearchPath',
        cleanBuild: cleanBuild,
        buildType: "${buildType}",
        buildDir: "_build_${buildType}",
        generator: "Ninja",
        cmakeArgs: "${cmakeArgs} -DCMAKE_BUILD_TYPE=${buildType} ${extraArgs}",
        steps: [[args: "--target package --config ${buildType}  --parallel", withCmake: true]]
    )
}

def run(what) {
    if(isUnix()) {
        sh "${what}"
    } else {
        bat "${what}"
    }
}

//##########################################
//the actual build process
//##########################################

// instantiate a build on an appropriate node
def doBuild(buildName, buildAgent, buildFlags) {
    return runOnNode(buildName, buildAgent, {

        def extraArgs = ""
        def buildEnv = []
        def scmVars = [:]

        stage("Git checkout and ENV setup (${buildName})") {
            if("cc" in buildFlags) {
                cc = buildFlags["cc"]
                buildEnv.add("CC=${cc}")
                extraArgs += " -DCMAKE_C_COMPILER=${cc}"
            }
            if("cxx" in buildFlags) {
                cxx = buildFlags["cxx"]
                buildEnv.add("CXX=${cxx}")
                extraArgs += " -DCMAKE_CXX_COMPILER=${cxx}"
                
            }
            if("msvc_version" in buildFlags) {
                // visual studio toolset selection via vcvarsall env
                buildEnv = buildEnv + getVsBuildEnv(buildFlags["arch"], buildFlags["msvc_version"])
                buildEnv.add("MSBUILDDISABLENODEREUSE=1") //fixes spurious windows failures

                msvc_toolset = buildFlags["msvc_version"].replace(".","") // 14.1 -> 141
                extraArgs += " -DMSVC_TOOLSET_VERSION=${msvc_toolset}" //needed for binary download URL resolution
                extraArgs += " -DCMAKE_CXX_COMPILER=cl -DCMAKE_C_COMPILER=cl"
            }

            print("DEBUG extraArgs=${extraArgs}")
            scmVars = checkoutGit()
            print("DEBUG scmVars=${scmVars}")
        }

        stage("Cmake Release Build (${buildName})") {
            print("${buildName} --  running cmake Release")
            withEnv(buildEnv) {
                runCmake("Release", "${cmakeArgsRelease}" + "${extraArgs}" )
            }
        } 

        stage("Unit Tests Release (${buildName})") {
            dir("_build_Release") {
                ctest(
                    installation: 'InSearchPath',
                    arguments: "--verbose --build-config Release -R '^Test.*'"
                )
                junit("**/*gtestresults.xml")

            }
        }

        stage("Integration Tests Release (${buildName})") {
            dir("_build_Release") {
                timeout(time: 10, unit: 'MINUTES') {
                    ctest(
                        installation: 'InSearchPath',
                        arguments: "--verbose --build-config Release -R '^ITest.*'"
                    )
                }
                junit("**/*gtestresults.xml")

            }
        }

        stage("Archiving Release Build (${buildName})") {
            try {
                archiveToArtifactory(scmVars, "_build_Release/${artifactName}-*.zip")
            } catch(e) {
                //make sure we save the finished artifacts before failing the build 
                print("WARNING: archiving to artifactory failed, archiving to jenkins instead and failing: exception: ${e}")
                archiveArtifacts(artifacts: "_build_Release/${artifactName}-*.zip", fingerprint: true)
                throw e
            }
        }

        if(buildDebugBin) {
            stage("Cmake Debug Build (${buildName})") {
                print("${buildName} --  running cmake Debug")
                withEnv(buildEnv) {
                    runCmake("Debug", extraArgs)
                }
            }

            stage("Debug Bundle Packages (${buildName})") {
                run "python ${dockerImageDir}/package.py \"_build_Release/${artifactName}-*-Release.zip\" \"_build_Debug/${artifactName}-*-Debug.zip\""
                archiveToArtifactory(scmVars, "_build_Debug/${artifactName}-*.zip")
                archiveToArtifactory(scmVars, "${artifactName}-*.zip")

                // safe the PDB files on windows
                if(!isUnix()) {
                    // package PDB files without rebuilding
                    def pdbArchive = "_build_Debug/IntegrationBus-${buildName}-PDB.zip"
                    run "python -mzipfile -c ${pdbArchive} _build_Debug/package-pdb/ _build_Release/package-pdb/"
                    archiveToArtifactory(scmVars, pdbArchive)
                }
            }
        }
    })
}

// node main entry. parallel invocation of all builds, packaging
node {
    // pipeline settings
    properties([
        buildDiscarder(logRotator(numToKeepStr: "${keepNumBuilds}")),
    ])   

    def builds = [:]

    // "Name of the target" : "Name of the target", "required node label", "generator name")
    builds.put("VS2017-Win64", doBuild("VS2017-Win64", "ninja && buildtools2019", ["arch":"x64", "msvc_version":"14.1"]) )
    builds.put("VS2015-Win64", doBuild("VS2015-Win64", "ninja && buildtools2019", ["arch":"x64", "msvc_version":"14.0"]) )
    builds.put("VS2017-Win32", doBuild("VS2017-Win32", "ninja && buildtools2019", ["arch":"x86", "msvc_version":"14.1"]) )
    builds.put("VS2015-Win32", doBuild("VS2015-Win32", "ninja && buildtools2019", ["arch":"x86", "msvc_version":"14.0"]) )
    builds.put("Ubuntu-clang", doBuild("Ubuntu-clang", "docker && linux", ["cc":"clang", "cxx":"clang++"]) )
    builds.put("Ubuntu-gcc"  , doBuild("Ubuntu-gcc",   "docker && linux", ["cc": "gcc",  "cxx":"g++"]) )
    
    parallel(builds)

    stage("Publishing Build Info") {
        if(publishToArtifactory) {
            artifactoryServer.publishBuildInfo(artifactoryBuildInfo)
        } else {
            print("INFO: skipping publishing build info to artifactory because of user request")
        }
    }
}
